{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "DM2024-Lab1-Homework.ipynb",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 9658575,
          "sourceType": "datasetVersion",
          "datasetId": 5900608
        },
        {
          "sourceId": 9724135,
          "sourceType": "datasetVersion",
          "datasetId": 5949933
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorSwankyTiger/DM2024-Lab1-Homework/blob/main/DM2024_Lab1_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "qggwWSsNw1Po"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "vitohung_helpers_path = kagglehub.dataset_download('vitohung/helpers')\n",
        "vitohung_data_mining_helpers_path = kagglehub.dataset_download('vitohung/data-mining-helpers')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "5yVFUtg1w1Pr"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorSwankyTiger/DM2024-Lab1-Homework/blob/main/DM2024-Lab1-Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Student Information\n",
        "Name:洪振庭\n",
        "\n",
        "Student ID:110000223\n",
        "\n",
        "GitHub ID:"
      ],
      "metadata": {
        "id": "OChHZxPtMXuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "nD2Qbo46MXur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions"
      ],
      "metadata": {
        "id": "hSLyFdMtMXur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. First: do the **take home** exercises in the [DM2024-Lab1-Master](https://github.com/didiersalazar/DM2024-Lab1-Master.git). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
        "\n",
        "\n",
        "2. Second: follow the same process from the [DM2024-Lab1-Master](https://github.com/didiersalazar/DM2024-Lab1-Master.git) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
        "    - Download the [the new dataset](https://huggingface.co/datasets/Senem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data). The dataset contains a `sentiment` and `comment` columns, with the sentiment labels being: 'nostalgia' and 'not nostalgia'. Read the specificiations of the dataset for background details.\n",
        "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
        "\n",
        "\n",
        "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
        "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas.\n",
        "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Scikit-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
        "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Note that for the TF-IDF features you might need to use other type of NB classifier different than the one in the Master Notebook. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
        "\n",
        "\n",
        "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be handled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
        "\n",
        "\n",
        "5. Fifth: It's hard for us to follow if your code is messy, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
        "\n",
        "\n",
        "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/didiersalazar/DM2024-Lab1-Master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (October 27th 11:59 pm, Sunday)__."
      ],
      "metadata": {
        "id": "QMVrucI5MXur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download and setup (Maybe different by enviroment and device)\n",
        "\n",
        "This part is download the HW dataset from hugging face using kaggle and colab note book, you can download data into your local PC."
      ],
      "metadata": {
        "id": "SKhejVH4w1Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/spaces/AP123/IllusionDiffusion"
      ],
      "metadata": {
        "id": "TA2YwJehOIXw",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:46:06.198383Z",
          "iopub.execute_input": "2024-10-26T01:46:06.198824Z",
          "iopub.status.idle": "2024-10-26T01:46:07.959433Z",
          "shell.execute_reply.started": "2024-10-26T01:46:06.198786Z",
          "shell.execute_reply": "2024-10-26T01:46:07.957749Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd IllusionDiffusion"
      ],
      "metadata": {
        "id": "DY8r5hHKONlI",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:46:07.962292Z",
          "iopub.execute_input": "2024-10-26T01:46:07.962862Z",
          "iopub.status.idle": "2024-10-26T01:46:07.973818Z",
          "shell.execute_reply.started": "2024-10-26T01:46:07.962797Z",
          "shell.execute_reply": "2024-10-26T01:46:07.972445Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r requirements.txt -q\n",
        "!pip install jupyterlab-lsp== 5.0.3\n",
        "!pip install pipreqs"
      ],
      "metadata": {
        "id": "UhwmeUBnOTwP",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:46:07.976136Z",
          "iopub.execute_input": "2024-10-26T01:46:07.97772Z",
          "iopub.status.idle": "2024-10-26T01:46:25.941947Z",
          "shell.execute_reply.started": "2024-10-26T01:46:07.977554Z",
          "shell.execute_reply": "2024-10-26T01:46:25.94013Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "bJkeibEVOdYq",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:46:25.94595Z",
          "iopub.execute_input": "2024-10-26T01:46:25.946552Z",
          "iopub.status.idle": "2024-10-26T01:46:41.353359Z",
          "shell.execute_reply.started": "2024-10-26T01:46:25.946482Z",
          "shell.execute_reply": "2024-10-26T01:46:41.351625Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spaces"
      ],
      "metadata": {
        "id": "brPspFPKPgnT",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:46:41.356542Z",
          "iopub.execute_input": "2024-10-26T01:46:41.35742Z",
          "iopub.status.idle": "2024-10-26T01:46:56.853111Z",
          "shell.execute_reply.started": "2024-10-26T01:46:41.357213Z",
          "shell.execute_reply": "2024-10-26T01:46:56.851402Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "odon814-OHzO",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:46:56.855154Z",
          "iopub.execute_input": "2024-10-26T01:46:56.855676Z",
          "iopub.status.idle": "2024-10-26T01:47:06.758692Z",
          "shell.execute_reply.started": "2024-10-26T01:46:56.855618Z",
          "shell.execute_reply": "2024-10-26T01:47:06.756794Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "yv8m9lfUNi_Y",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:47:06.760565Z",
          "iopub.execute_input": "2024-10-26T01:47:06.761008Z",
          "iopub.status.idle": "2024-10-26T01:47:21.914945Z",
          "shell.execute_reply.started": "2024-10-26T01:47:06.760961Z",
          "shell.execute_reply": "2024-10-26T01:47:21.913419Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "2ae71wXzMfv3",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:47:21.917292Z",
          "iopub.execute_input": "2024-10-26T01:47:21.917847Z",
          "iopub.status.idle": "2024-10-26T01:47:21.94951Z",
          "shell.execute_reply.started": "2024-10-26T01:47:21.917783Z",
          "shell.execute_reply": "2024-10-26T01:47:21.948074Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"hf://datasets/Senem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data.csv\")"
      ],
      "metadata": {
        "id": "lUu5c_QSQzng",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:51:25.882457Z",
          "iopub.execute_input": "2024-10-26T01:51:25.882871Z",
          "iopub.status.idle": "2024-10-26T01:51:26.066681Z",
          "shell.execute_reply.started": "2024-10-26T01:51:25.882832Z",
          "shell.execute_reply": "2024-10-26T01:51:26.06474Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)\n"
      ],
      "metadata": {
        "id": "f0-x-v_xRBYM",
        "execution": {
          "iopub.status.busy": "2024-10-26T01:51:29.183885Z",
          "iopub.execute_input": "2024-10-26T01:51:29.184332Z",
          "iopub.status.idle": "2024-10-26T01:51:29.198763Z",
          "shell.execute_reply.started": "2024-10-26T01:51:29.184285Z",
          "shell.execute_reply": "2024-10-26T01:51:29.197276Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data preprocessing"
      ],
      "metadata": {
        "id": "UuU1-HeQw1Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test mark\n",
        "categories = ['not nostalgia','nostalgia']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:51:32.162519Z",
          "iopub.execute_input": "2024-10-26T01:51:32.162947Z",
          "iopub.status.idle": "2024-10-26T01:51:32.168867Z",
          "shell.execute_reply.started": "2024-10-26T01:51:32.162909Z",
          "shell.execute_reply": "2024-10-26T01:51:32.167422Z"
        },
        "trusted": true,
        "id": "OC7CajYUw1Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST necessary for when working with external scripts\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:47:22.152646Z",
          "iopub.execute_input": "2024-10-26T01:47:22.153023Z",
          "iopub.status.idle": "2024-10-26T01:47:22.167961Z",
          "shell.execute_reply.started": "2024-10-26T01:47:22.152985Z",
          "shell.execute_reply": "2024-10-26T01:47:22.166395Z"
        },
        "trusted": true,
        "id": "3pAyZRUpw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "print(df[0:2])\n",
        "for text in df[\"comment\"][:2]:\n",
        "    print(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:51:35.472923Z",
          "iopub.execute_input": "2024-10-26T01:51:35.473408Z",
          "iopub.status.idle": "2024-10-26T01:51:35.483846Z",
          "shell.execute_reply.started": "2024-10-26T01:51:35.473365Z",
          "shell.execute_reply": "2024-10-26T01:51:35.482295Z"
        },
        "trusted": true,
        "id": "ScYsBr4Yw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "df['nostalgia']=pd.Series(np.arange(df['sentiment'].shape[0]))\n",
        "for i in range(0,df['sentiment'].shape[0]):\n",
        "    if(df['sentiment'][i]=='nostalgia'): df.loc[i,'nostalgia'] = 1\n",
        "    else: df.loc[i,'nostalgia'] = 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:51:38.506504Z",
          "iopub.execute_input": "2024-10-26T01:51:38.506984Z",
          "iopub.status.idle": "2024-10-26T01:51:38.983488Z",
          "shell.execute_reply.started": "2024-10-26T01:51:38.506939Z",
          "shell.execute_reply": "2024-10-26T01:51:38.981818Z"
        },
        "trusted": true,
        "id": "hXpwAIyUw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:51:41.168119Z",
          "iopub.execute_input": "2024-10-26T01:51:41.168976Z",
          "iopub.status.idle": "2024-10-26T01:51:41.181455Z",
          "shell.execute_reply.started": "2024-10-26T01:51:41.168927Z",
          "shell.execute_reply": "2024-10-26T01:51:41.180099Z"
        },
        "trusted": true,
        "id": "qPjk_Le1w1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:52:55.239184Z",
          "iopub.execute_input": "2024-10-26T01:52:55.239731Z",
          "iopub.status.idle": "2024-10-26T01:52:55.262847Z",
          "shell.execute_reply.started": "2024-10-26T01:52:55.239683Z",
          "shell.execute_reply": "2024-10-26T01:52:55.261103Z"
        },
        "trusted": true,
        "id": "FD6HVu0xw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.isnull().apply(lambda x: dmh.check_missing_values(x))\n",
        "df.drop_duplicates(keep=False, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:54:05.874789Z",
          "iopub.execute_input": "2024-10-26T01:54:05.875273Z",
          "iopub.status.idle": "2024-10-26T01:54:05.896444Z",
          "shell.execute_reply.started": "2024-10-26T01:54:05.8752Z",
          "shell.execute_reply": "2024-10-26T01:54:05.894808Z"
        },
        "trusted": true,
        "id": "kdGP51oKw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/kaggle/input/helpers')\n",
        "import data_mining_helpers as dmh\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:51:53.425834Z",
          "iopub.execute_input": "2024-10-26T01:51:53.426297Z",
          "iopub.status.idle": "2024-10-26T01:51:53.432886Z",
          "shell.execute_reply.started": "2024-10-26T01:51:53.426234Z",
          "shell.execute_reply": "2024-10-26T01:51:53.431395Z"
        },
        "trusted": true,
        "id": "hd0RXWm2w1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.sentiment.value_counts())\n",
        "\n",
        "#print out count of distribuition\n",
        "df.sentiment.value_counts().plot(kind = 'bar',\n",
        "                                    title = 'Distribution',\n",
        "                                    ylim = [0, 800],\n",
        "                                    rot = 0, fontsize = 11, figsize = (8,3))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:54:38.666531Z",
          "iopub.execute_input": "2024-10-26T01:54:38.667001Z",
          "iopub.status.idle": "2024-10-26T01:54:39.448314Z",
          "shell.execute_reply.started": "2024-10-26T01:54:38.666959Z",
          "shell.execute_reply": "2024-10-26T01:54:39.446456Z"
        },
        "trusted": true,
        "id": "T7r6Jrz2w1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "counts = count_vect.fit_transform(df.comment)\n",
        "print(counts[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:56:15.751144Z",
          "iopub.execute_input": "2024-10-26T01:56:15.751656Z",
          "iopub.status.idle": "2024-10-26T01:56:15.833949Z",
          "shell.execute_reply.started": "2024-10-26T01:56:15.75161Z",
          "shell.execute_reply": "2024-10-26T01:56:15.832669Z"
        },
        "trusted": true,
        "id": "J4rK1Vp1w1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = count_vect.get_feature_names_out()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T01:56:49.850315Z",
          "iopub.execute_input": "2024-10-26T01:56:49.851361Z",
          "iopub.status.idle": "2024-10-26T01:56:49.859909Z",
          "shell.execute_reply.started": "2024-10-26T01:56:49.851297Z",
          "shell.execute_reply": "2024-10-26T01:56:49.85874Z"
        },
        "trusted": true,
        "id": "Hs3K-Bslw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#hitmap of document words\n",
        "plot_x = [\"term_\"+str(i) for i in feature_names[0:20]]\n",
        "plot_y = [\"doc_\"+ str(i) for i in df.index[0:20]]\n",
        "plot_z = counts[0:20, 0:20].toarray()\n",
        "df_todraw = pd.DataFrame(plot_z, columns = plot_x, index = plot_y)\n",
        "plt.subplots(figsize=(9, 7))\n",
        "ax = sns.heatmap(df_todraw,\n",
        "                 cmap=\"PuRd\",\n",
        "                 vmin=0, vmax=1, annot=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:00:02.836685Z",
          "iopub.execute_input": "2024-10-26T02:00:02.837111Z",
          "iopub.status.idle": "2024-10-26T02:00:05.174001Z",
          "shell.execute_reply.started": "2024-10-26T02:00:02.837072Z",
          "shell.execute_reply": "2024-10-26T02:00:05.172597Z"
        },
        "trusted": true,
        "id": "DNfr9obTw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hitmap\n",
        "term_document_matrix = np.random.poisson(0.1, (50, 50))\n",
        "\n",
        "df_tdm = pd.DataFrame(term_document_matrix, columns=[\"term_\"+str(i) for i in feature_names[0:50]], index=[\"doc_\"+ str(i) for i in df.index[0:50]])\n",
        "df_sampled = df_tdm.sample(n=20, axis=0).sample(n=20, axis=1)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df_sampled, cmap=\"PuRd\", vmin=0, vmax=df_sampled.values.max(), annot=False, cbar=True)\n",
        "plt.title(\"Sampled Term-Document Matrix Heatmap\")\n",
        "plt.xlabel(\"Terms\")\n",
        "plt.ylabel(\"Documents\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:07:24.878954Z",
          "iopub.execute_input": "2024-10-26T02:07:24.879423Z",
          "iopub.status.idle": "2024-10-26T02:07:25.698566Z",
          "shell.execute_reply.started": "2024-10-26T02:07:24.879381Z",
          "shell.execute_reply": "2024-10-26T02:07:25.697232Z"
        },
        "trusted": true,
        "id": "8kwra2-8w1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_frequencies = []\n",
        "for j in range(0,counts.shape[1]):\n",
        "    term_frequencies.append(sum(counts[:,j].toarray()))\n",
        "term_frequencies = np.asarray(counts.sum(axis=0))[0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:14:31.876447Z",
          "iopub.execute_input": "2024-10-26T02:14:31.876912Z",
          "iopub.status.idle": "2024-10-26T02:14:39.478089Z",
          "shell.execute_reply.started": "2024-10-26T02:14:31.876871Z",
          "shell.execute_reply": "2024-10-26T02:14:39.47633Z"
        },
        "trusted": true,
        "id": "R2WDwfCfw1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(100, 10))\n",
        "g = sns.barplot(x=count_vect.get_feature_names_out()[:300],\n",
        "            y=term_frequencies[:300])\n",
        "g.set_xticklabels(count_vect.get_feature_names_out()[:300], rotation = 90);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:14:44.261966Z",
          "iopub.execute_input": "2024-10-26T02:14:44.262446Z",
          "iopub.status.idle": "2024-10-26T02:14:48.55631Z",
          "shell.execute_reply.started": "2024-10-26T02:14:44.262405Z",
          "shell.execute_reply": "2024-10-26T02:14:48.554737Z"
        },
        "trusted": true,
        "id": "JIoCMEh_w1Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly\n",
        "!pip install chart-studio"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:15:46.732959Z",
          "iopub.execute_input": "2024-10-26T02:15:46.733427Z",
          "iopub.status.idle": "2024-10-26T02:16:16.878597Z",
          "shell.execute_reply.started": "2024-10-26T02:15:46.733383Z",
          "shell.execute_reply": "2024-10-26T02:16:16.876852Z"
        },
        "trusted": true,
        "id": "IcCfh9jlw1Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chart_studio\n",
        "from chart_studio import plotly\n",
        "#from plotly import tools\n",
        "import plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "plt.subplots(figsize=(100, 10))\n",
        "g = sns.barplot(x=count_vect.get_feature_names_out()[:300],\n",
        "            y=term_frequencies[:300])\n",
        "g.set_xticklabels(count_vect.get_feature_names_out()[:300], rotation = 90);\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:17:17.514376Z",
          "iopub.execute_input": "2024-10-26T02:17:17.514898Z",
          "iopub.status.idle": "2024-10-26T02:17:21.872759Z",
          "shell.execute_reply.started": "2024-10-26T02:17:17.51485Z",
          "shell.execute_reply": "2024-10-26T02:17:21.871585Z"
        },
        "trusted": true,
        "id": "Dt1nCXDBw1Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.offline as pof\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "features = count_vect.get_feature_names_out()[:300]\n",
        "term_frequencies = term_frequencies[:300]\n",
        "\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(x=features, y=term_frequencies)\n",
        "])\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Term Frequency Distribution\",\n",
        "    xaxis_title=\"Terms\",\n",
        "    yaxis_title=\"Frequency\",\n",
        "    xaxis_tickangle=-90,\n",
        "    height=500,\n",
        "    width=1200\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:18:07.274453Z",
          "iopub.execute_input": "2024-10-26T02:18:07.274928Z",
          "iopub.status.idle": "2024-10-26T02:18:07.310796Z",
          "shell.execute_reply.started": "2024-10-26T02:18:07.274885Z",
          "shell.execute_reply": "2024-10-26T02:18:07.307805Z"
        },
        "trusted": true,
        "id": "i2ArZp4Jw1Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Assuming X_counts is your term-document matrix\n",
        "# Compute term frequencies (total count across all documents)\n",
        "term_frequencies = np.array(counts.sum(axis=0)).flatten()\n",
        "\n",
        "# Get the vocabulary (term names)\n",
        "vocab = count_vect.get_feature_names_out()\n",
        "\n",
        "df_term_frequencies = pd.DataFrame({\n",
        "    'Term': vocab,\n",
        "    'Frequency': term_frequencies\n",
        "})\n",
        "\n",
        "# Step 1: Sort by frequency and keep only top N terms (e.g., top 100)\n",
        "top_n = 300\n",
        "df_top_n = df_term_frequencies.sample(n=top_n)\n",
        "\n",
        "# Step 2: Plot the top N terms using Plotly\n",
        "fig = px.bar(df_top_n, x='Term', y='Frequency')\n",
        "\n",
        "# Step 3: Customize the plot\n",
        "fig.update_layout(\n",
        "    title=f\"Random {top_n} Frequent Terms\",\n",
        "    xaxis_tickangle=-90,  # Rotate x-axis labels for readability\n",
        "    height=500,\n",
        "    width=1200,\n",
        "    xaxis_title=\"Terms\",\n",
        "    yaxis_title=\"Frequency\"\n",
        ")\n",
        "\n",
        "# Show the interactive plot\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:18:51.97291Z",
          "iopub.execute_input": "2024-10-26T02:18:51.973527Z",
          "iopub.status.idle": "2024-10-26T02:18:54.401629Z",
          "shell.execute_reply.started": "2024-10-26T02:18:51.973479Z",
          "shell.execute_reply": "2024-10-26T02:18:54.397987Z"
        },
        "trusted": true,
        "id": "9HCGkE-Cw1Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute term frequencies (total count across all documents)\n",
        "term_frequencies = np.array(counts.sum(axis=0)).flatten()\n",
        "\n",
        "# Get the vocabulary (term names)\n",
        "vocab = count_vect.get_feature_names_out()\n",
        "\n",
        "df_term_frequencies = pd.DataFrame({\n",
        "    'Term': vocab,\n",
        "    'Frequency': term_frequencies\n",
        "})\n",
        "\n",
        "# Step 1: Sort by frequency and keep only top N terms (e.g., top 100)\n",
        "top_n = 300\n",
        "df_top_n = df_term_frequencies.nlargest(top_n, 'Frequency')\n",
        "\n",
        "# Step 2: Plot the top N terms using Plotly\n",
        "fig = px.bar(df_top_n, x='Term', y='Frequency')\n",
        "\n",
        "# Step 3: Customize the plot\n",
        "fig.update_layout(\n",
        "    title=f\"Top {top_n} Most Frequent Terms\",\n",
        "    xaxis_tickangle=-90,  # Rotate x-axis labels for readability\n",
        "    height=500,\n",
        "    width=1200,\n",
        "    xaxis_title=\"Terms\",\n",
        "    yaxis_title=\"Frequency\"\n",
        ")\n",
        "\n",
        "# Show the interactive plot\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:19:31.119511Z",
          "iopub.execute_input": "2024-10-26T02:19:31.119949Z",
          "iopub.status.idle": "2024-10-26T02:19:31.215114Z",
          "shell.execute_reply.started": "2024-10-26T02:19:31.119907Z",
          "shell.execute_reply": "2024-10-26T02:19:31.21353Z"
        },
        "trusted": true,
        "id": "WRUqVIHyw1Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "term_frequencies_log = [math.log(i) for i in term_frequencies]\n",
        "plt.subplots(figsize=(100, 10))\n",
        "g = sns.barplot(x=count_vect.get_feature_names_out()[:300],\n",
        "                y=term_frequencies_log[:300])\n",
        "g.set_xticklabels(count_vect.get_feature_names_out()[:300], rotation = 90);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:19:51.052794Z",
          "iopub.execute_input": "2024-10-26T02:19:51.053298Z",
          "iopub.status.idle": "2024-10-26T02:19:56.300979Z",
          "shell.execute_reply.started": "2024-10-26T02:19:51.053251Z",
          "shell.execute_reply": "2024-10-26T02:19:56.29893Z"
        },
        "trusted": true,
        "id": "G5m-R3Xbw1P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute term frequencies (total count across all documents)\n",
        "term_frequencies = np.array(counts.sum(axis=0)).flatten()\n",
        "term_frequencies_log = [math.log(i) for i in term_frequencies]\n",
        "\n",
        "# Get the vocabulary (term names)\n",
        "vocab = count_vect.get_feature_names_out()\n",
        "\n",
        "df_term_frequencies = pd.DataFrame({\n",
        "    'Term': vocab,\n",
        "    'Frequency': term_frequencies_log\n",
        "})\n",
        "\n",
        "# Step 1: Sort by frequency and keep only top N terms (e.g., top 100)\n",
        "top_n = 300\n",
        "df_top_n = df_term_frequencies.nlargest(top_n, 'Frequency')\n",
        "\n",
        "# Step 2: Plot the top N terms using Plotly\n",
        "fig = px.bar(df_top_n, x='Term', y='Frequency')\n",
        "\n",
        "# Step 3: Customize the plot\n",
        "fig.update_layout(\n",
        "    title=f\"Top {top_n} Most Frequent Terms\",\n",
        "    xaxis_tickangle=-90,  # Rotate x-axis labels for readability\n",
        "    height=500,\n",
        "    width=1200,\n",
        "    xaxis_title=\"Terms\",\n",
        "    yaxis_title=\"Frequency\"\n",
        ")\n",
        "\n",
        "# Show the interactive plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:20:17.287208Z",
          "iopub.execute_input": "2024-10-26T02:20:17.287747Z",
          "iopub.status.idle": "2024-10-26T02:20:17.39056Z",
          "shell.execute_reply.started": "2024-10-26T02:20:17.287704Z",
          "shell.execute_reply": "2024-10-26T02:20:17.389327Z"
        },
        "trusted": true,
        "id": "Yhvf3av_w1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_counts is your term-document matrix\n",
        "# Compute term frequencies (total count across all documents)\n",
        "term_frequencies = np.array(counts.sum(axis=0)).flatten()\n",
        "term_frequencies_log = [math.log(i) for i in term_frequencies]\n",
        "\n",
        "# Get the vocabulary (term names)\n",
        "vocab = count_vect.get_feature_names_out()\n",
        "\n",
        "df_term_frequencies = pd.DataFrame({\n",
        "    'Term': vocab,\n",
        "    'Frequency': term_frequencies_log\n",
        "})\n",
        "\n",
        "# Step 1: Sort by frequency and keep only top N terms (e.g., top 100)\n",
        "top_n = 300\n",
        "df_top_n = df_term_frequencies.sample(n=top_n)\n",
        "\n",
        "# Step 2: Plot the top N terms using Plotly\n",
        "fig = px.bar(df_top_n, x='Term', y='Frequency')\n",
        "\n",
        "# Step 3: Customize the plot\n",
        "fig.update_layout(\n",
        "    title=f\" Random {top_n} Frequent Terms\",\n",
        "    xaxis_tickangle=-90,  # Rotate x-axis labels for readability\n",
        "    height=500,\n",
        "    width=1200,\n",
        "    xaxis_title=\"Terms\",\n",
        "    yaxis_title=\"Frequency\"\n",
        ")\n",
        "\n",
        "# Show the interactive plot\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:20:52.529842Z",
          "iopub.execute_input": "2024-10-26T02:20:52.530313Z",
          "iopub.status.idle": "2024-10-26T02:20:52.628999Z",
          "shell.execute_reply.started": "2024-10-26T02:20:52.530268Z",
          "shell.execute_reply": "2024-10-26T02:20:52.627702Z"
        },
        "trusted": true,
        "id": "4WYzDIchw1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create separate DataFrames for each category\n",
        "categories = df['sentiment'].unique()  # Get unique category labels\n",
        "category_dfs = {}  # Dictionary to store DataFrames for each category\n",
        "\n",
        "for category in categories:\n",
        "    # Filter the original DataFrame by category\n",
        "    category_dfs[category] = df[df['sentiment'] == category].copy()\n",
        "\n",
        "# Function to create term-document frequency DataFrame for each category\n",
        "def create_term_document_df(df):\n",
        "    count_vect = CountVectorizer()  # Initialize the CountVectorizer\n",
        "    X_counts = count_vect.fit_transform(df['comment'])  # Transform the text data into word counts\n",
        "\n",
        "    # Get the unique words (vocabulary) from the vectorizer\n",
        "    words = count_vect.get_feature_names_out()\n",
        "\n",
        "    # Create a DataFrame where rows are documents and columns are words\n",
        "    term_document_df = pd.DataFrame(X_counts.toarray(), columns=words)\n",
        "\n",
        "    return term_document_df\n",
        "\n",
        "# Create term-document frequency DataFrames for each category\n",
        "term_document_dfs = {}  # Dictionary to store term-document DataFrames for each category\n",
        "\n",
        "for category in categories:\n",
        "    term_document_dfs[category] = create_term_document_df(category_dfs[category])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:30:04.323791Z",
          "iopub.execute_input": "2024-10-26T02:30:04.324288Z",
          "iopub.status.idle": "2024-10-26T02:30:04.434618Z",
          "shell.execute_reply.started": "2024-10-26T02:30:04.324212Z",
          "shell.execute_reply": "2024-10-26T02:30:04.431771Z"
        },
        "trusted": true,
        "id": "ygKneHtJw1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the filtered DataFrame for one of the categories, feel free to change the number in the vector\n",
        "category_number=0 #You can change it from 0 to 3\n",
        "print(f\"Filtered Term-Document Frequency DataFrame for Category {categories[category_number]}:\")\n",
        "term_document_dfs[categories[category_number]]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:30:14.813014Z",
          "iopub.execute_input": "2024-10-26T02:30:14.813917Z",
          "iopub.status.idle": "2024-10-26T02:30:14.849385Z",
          "shell.execute_reply.started": "2024-10-26T02:30:14.813843Z",
          "shell.execute_reply": "2024-10-26T02:30:14.847827Z"
        },
        "trusted": true,
        "id": "r49KyD97w1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Sum over all documents to get total frequency for each word\n",
        "category_number=0 #You can change it from 0 to 3\n",
        "word_counts = term_document_dfs[categories[category_number]].sum(axis=0).to_numpy()\n",
        "\n",
        "# Visualize the frequency distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(word_counts, bins=5000, color='blue', edgecolor='black')\n",
        "plt.title(f'Term Frequency Distribution for Category {categories[category_number]}')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Number of Terms')\n",
        "plt.xlim(1, 200)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:30:46.735686Z",
          "iopub.execute_input": "2024-10-26T02:30:46.736186Z",
          "iopub.status.idle": "2024-10-26T02:30:56.647177Z",
          "shell.execute_reply.started": "2024-10-26T02:30:46.73613Z",
          "shell.execute_reply": "2024-10-26T02:30:56.645512Z"
        },
        "trusted": true,
        "id": "eeQd4sKCw1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_number=1 #You can change it from 0 to 1\n",
        "word_counts = term_document_dfs[categories[category_number]].sum(axis=0).to_numpy()\n",
        "\n",
        "# Sort the term frequencies in descending order\n",
        "sorted_indices = np.argsort(word_counts)  # Get indices of sorted frequencies\n",
        "sorted_counts = np.sort(word_counts)[::-1]  # Sort frequencies in descending order\n",
        "\n",
        "# Calculate the index corresponding to the top 5% most frequent terms\n",
        "total_terms = len(sorted_counts)\n",
        "top_5_percent_index = int(0.05 * total_terms)\n",
        "\n",
        "# Get the indices of the top 5% most frequent terms\n",
        "top_5_percent_indices = sorted_indices[:top_5_percent_index]\n",
        "\n",
        "# Filter terms that belong to the top 5% based on their rank\n",
        "filtered_words = [count_vect.get_feature_names_out()[i] for i in top_5_percent_indices]\n",
        "\n",
        "print(f\"Category: {categories[category_number]}\")\n",
        "print(f\"Number of terms in top 5%: {top_5_percent_index}\")\n",
        "print(f\"Filtered terms: {filtered_words}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:31:22.625318Z",
          "iopub.execute_input": "2024-10-26T02:31:22.625787Z",
          "iopub.status.idle": "2024-10-26T02:31:22.865664Z",
          "shell.execute_reply.started": "2024-10-26T02:31:22.625739Z",
          "shell.execute_reply": "2024-10-26T02:31:22.864211Z"
        },
        "trusted": true,
        "id": "poZ3TgCmw1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_number=0 #You can change it from 0 to 1\n",
        "word_counts = term_document_dfs[categories[category_number]].sum(axis=0).to_numpy()\n",
        "\n",
        "# Sort the term frequencies in ascending order and get sorted indices\n",
        "sorted_indices = np.argsort(word_counts)  # Get indices of sorted frequencies\n",
        "sorted_counts = word_counts[sorted_indices]  # Sort frequencies\n",
        "\n",
        "# Calculate the index corresponding to the bottom 1% least frequent terms\n",
        "total_terms = len(sorted_counts)\n",
        "bottom_1_percent_index = int(0.01 * total_terms)\n",
        "\n",
        "# Get the indices of the bottom 1% least frequent terms\n",
        "bottom_1_percent_indices = sorted_indices[:bottom_1_percent_index]\n",
        "\n",
        "# Filter terms that belong to the bottom 1% based on their rank\n",
        "filtered_words = [count_vect.get_feature_names_out()[i] for i in bottom_1_percent_indices]\n",
        "\n",
        "print(f\"Category: {categories[category_number]}\")\n",
        "print(f\"Number of terms in bottom 1%: {bottom_1_percent_index}\")\n",
        "print(f\"Filtered terms: {filtered_words}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:31:54.566377Z",
          "iopub.execute_input": "2024-10-26T02:31:54.566853Z",
          "iopub.status.idle": "2024-10-26T02:31:54.634694Z",
          "shell.execute_reply.started": "2024-10-26T02:31:54.566812Z",
          "shell.execute_reply": "2024-10-26T02:31:54.633217Z"
        },
        "trusted": true,
        "id": "VGGSffJdw1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pami"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:33:50.030827Z",
          "iopub.execute_input": "2024-10-26T02:33:50.031381Z",
          "iopub.status.idle": "2024-10-26T02:34:06.035306Z",
          "shell.execute_reply.started": "2024-10-26T02:33:50.031321Z",
          "shell.execute_reply": "2024-10-26T02:34:06.033343Z"
        },
        "trusted": true,
        "id": "_Kpjtx51w1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PAMI\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:34:06.03737Z",
          "iopub.execute_input": "2024-10-26T02:34:06.037944Z",
          "iopub.status.idle": "2024-10-26T02:34:06.058077Z",
          "shell.execute_reply.started": "2024-10-26T02:34:06.037895Z",
          "shell.execute_reply": "2024-10-26T02:34:06.056561Z"
        },
        "trusted": true,
        "id": "L3HlvFTbw1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PAMI.extras.convert.DF2DB import DF2DB\n",
        "for category in term_document_dfs:\n",
        "    # Replace dots with underscores in the category name to avoid errors in the file creation\n",
        "    category_safe = category.replace('.', '_')\n",
        "\n",
        "    # Create the DenseFormatDF object and convert to a transactional database\n",
        "    obj = DF2DB(term_document_dfs[category])\n",
        "    obj.convert2TransactionalDatabase(f'td_freq_db_{category_safe}.csv', '>=', 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:35:01.387498Z",
          "iopub.execute_input": "2024-10-26T02:35:01.389739Z",
          "iopub.status.idle": "2024-10-26T02:35:40.802722Z",
          "shell.execute_reply.started": "2024-10-26T02:35:01.389676Z",
          "shell.execute_reply": "2024-10-26T02:35:40.801294Z"
        },
        "trusted": true,
        "id": "hXB3nk0mw1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PAMI.extras.dbStats import TransactionalDatabase as tds\n",
        "\n",
        "obj = tds.TransactionalDatabase('td_freq_db_nostalgia.csv')\n",
        "obj.run()\n",
        "obj.printStats()\n",
        "obj.plotGraphs()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:36:14.629814Z",
          "iopub.execute_input": "2024-10-26T02:36:14.630293Z",
          "iopub.status.idle": "2024-10-26T02:36:16.931524Z",
          "shell.execute_reply.started": "2024-10-26T02:36:14.630234Z",
          "shell.execute_reply": "2024-10-26T02:36:16.930166Z"
        },
        "trusted": true,
        "id": "sWPWY7sXw1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minSup=9\n",
        "obj1 = alg.FPGrowth(iFile='td_freq_db_nostalgia.csv', minSup=minSup)\n",
        "obj1.mine()\n",
        "frequentPatternsDF_nostalgia= obj1.getPatternsAsDataFrame()\n",
        "print('Total No of patterns: ' + str(len(frequentPatternsDF_nostalgia))) #print the total number of patterns\n",
        "print('Runtime: ' + str(obj1.getRuntime())) #measure the runtime\n",
        "obj1.save('freq_patterns_nostalgia_minSup9.txt') #save the patterns\n",
        "frequentPatternsDF_nostalgia"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:46:46.945936Z",
          "iopub.execute_input": "2024-10-26T02:46:46.946425Z",
          "iopub.status.idle": "2024-10-26T02:46:53.575359Z",
          "shell.execute_reply.started": "2024-10-26T02:46:46.946381Z",
          "shell.execute_reply": "2024-10-26T02:46:53.573913Z"
        },
        "trusted": true,
        "id": "w4zChFnKw1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minSup=9\n",
        "obj1 = alg.FPGrowth(iFile='td_freq_db_not nostalgia.csv', minSup=minSup)\n",
        "obj1.mine()\n",
        "frequentPatternsDF_not_nostalgia= obj1.getPatternsAsDataFrame()\n",
        "print('Total No of patterns: ' + str(len(frequentPatternsDF_nostalgia))) #print the total number of patterns\n",
        "print('Runtime: ' + str(obj1.getRuntime())) #measure the runtime\n",
        "obj1.save('freq_patterns_not_nostalgia_minSup9.txt') #save the patterns\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:46:42.43114Z",
          "iopub.execute_input": "2024-10-26T02:46:42.43165Z",
          "iopub.status.idle": "2024-10-26T02:46:43.875634Z",
          "shell.execute_reply.started": "2024-10-26T02:46:42.431605Z",
          "shell.execute_reply": "2024-10-26T02:46:43.874134Z"
        },
        "trusted": true,
        "id": "GgBNGWPMw1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We group together all of the dataframes related to our found patterns\n",
        "dfs = [frequentPatternsDF_nostalgia, frequentPatternsDF_not_nostalgia]\n",
        "\n",
        "\n",
        "# Identify patterns that appear in more than one category\n",
        "# Count how many times each pattern appears across all dataframes\n",
        "pattern_counts = {}\n",
        "for df_ in dfs:\n",
        "    for pattern in df_['Patterns']:\n",
        "        if pattern not in pattern_counts:\n",
        "            pattern_counts[pattern] = 1\n",
        "        else:\n",
        "            pattern_counts[pattern] += 1\n",
        "\n",
        "# Filter out patterns that appear in more than one dataframe\n",
        "unique_patterns = {pattern for pattern, count in pattern_counts.items() if count == 1}\n",
        "# Calculate the total number of patterns across all categories\n",
        "total_patterns_count = sum(len(df_) for df_ in dfs)\n",
        "# Calculate how many patterns were discarded\n",
        "discarded_patterns_count = total_patterns_count - len(unique_patterns)\n",
        "\n",
        "# For each category, filter the patterns to keep only the unique ones\n",
        "filtered_dfs = []\n",
        "for df_ in dfs:\n",
        "    filtered_df = df_[df_['Patterns'].isin(unique_patterns)]\n",
        "    filtered_dfs.append(filtered_df)\n",
        "\n",
        "# Merge the filtered dataframes into a final dataframe\n",
        "final_pattern_df = pd.concat(filtered_dfs, ignore_index=True)\n",
        "\n",
        "\n",
        "# Sort by support\n",
        "final_pattern_df = final_pattern_df.sort_values(by='Support', ascending=False)\n",
        "\n",
        "# Display the final result\n",
        "print(final_pattern_df)\n",
        "# Print the number of discarded patterns\n",
        "print(f\"Number of patterns discarded: {discarded_patterns_count}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:48:33.583316Z",
          "iopub.execute_input": "2024-10-26T02:48:33.58381Z",
          "iopub.status.idle": "2024-10-26T02:48:33.70778Z",
          "shell.execute_reply.started": "2024-10-26T02:48:33.583768Z",
          "shell.execute_reply": "2024-10-26T02:48:33.706337Z"
        },
        "trusted": true,
        "id": "Cyi8OwVQw1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert 'text' column into term-document matrix using CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_tdm = count_vect.fit_transform(df['comment'])  # X['text'] contains your text data\n",
        "terms = count_vect.get_feature_names_out()  # Original terms in the vocabulary\n",
        "\n",
        "# Tokenize the sentences into sets of unique words\n",
        "df['tokenized_comment'] = df['comment'].str.split().apply(set)\n",
        "\n",
        "# Initialize the pattern matrix\n",
        "pattern_matrix = pd.DataFrame(0, index=df.index, columns=final_pattern_df['Patterns'])\n",
        "\n",
        "# Iterate over each pattern and check if all words in the pattern are present in the tokenized sentence\n",
        "for pattern in final_pattern_df['Patterns']:\n",
        "    pattern_words = set(pattern.split())  # Tokenize pattern into words\n",
        "    pattern_matrix[pattern] = df['tokenized_comment'].apply(lambda x: 1 if pattern_words.issubset(x) else 0)\n",
        "\n",
        "# Convert the term-document matrix to a DataFrame for easy merging\n",
        "tdm_df = pd.DataFrame(X_tdm.toarray(), columns=terms, index=df.index)\n",
        "\n",
        "# Concatenate the original TDM and the pattern matrix to augment the features\n",
        "augmented_df = pd.concat([tdm_df, pattern_matrix], axis=1)\n",
        "\n",
        "augmented_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:51:08.388393Z",
          "iopub.execute_input": "2024-10-26T02:51:08.3889Z",
          "iopub.status.idle": "2024-10-26T02:53:43.292038Z",
          "shell.execute_reply.started": "2024-10-26T02:51:08.388859Z",
          "shell.execute_reply": "2024-10-26T02:53:43.290805Z"
        },
        "trusted": true,
        "id": "FOOmFXpow1P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap\n",
        "!pip install umap-learn\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:54:36.547902Z",
          "iopub.execute_input": "2024-10-26T02:54:36.548567Z",
          "iopub.status.idle": "2024-10-26T02:55:11.844066Z",
          "shell.execute_reply.started": "2024-10-26T02:54:36.548508Z",
          "shell.execute_reply": "2024-10-26T02:55:11.842623Z"
        },
        "trusted": true,
        "id": "4_P6ALI0w1P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying dimensionality reduction with only the document-term frequency data\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#This might take a couple of minutes to execute\n",
        "# Apply PCA, t-SNE, and UMAP to the data\n",
        "X_pca_tdm = PCA(n_components=2).fit_transform(tdm_df.values)\n",
        "X_tsne_tdm = TSNE(n_components=2).fit_transform(tdm_df.values)\n",
        "X_umap_tdm = umap.UMAP(n_components=2).fit_transform(tdm_df.values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-26T02:55:31.288347Z",
          "iopub.execute_input": "2024-10-26T02:55:31.288882Z",
          "iopub.status.idle": "2024-10-26T02:56:45.057104Z",
          "shell.execute_reply.started": "2024-10-26T02:55:31.288832Z",
          "shell.execute_reply": "2024-10-26T02:56:45.055406Z"
        },
        "trusted": true,
        "id": "iePKVEbkw1P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results in subplots\n",
        "col = ['coral', 'blue', 'black', 'orange']\n",
        "categories = X['category_name'].unique()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(30, 10))  # Create 3 subplots for PCA, t-SNE, and UMAP\n",
        "fig.suptitle('PCA, t-SNE, and UMAP Comparison')\n",
        "\n",
        "# Define a function to create a scatter plot for each method\n",
        "def plot_scatter(ax, X_reduced, title):\n",
        "    for c, category in zip(col, categories):\n",
        "        xs = X_reduced[X['category_name'] == category].T[0]\n",
        "        ys = X_reduced[X['category_name'] == category].T[1]\n",
        "        ax.scatter(xs, ys, c=c, marker='o', label=category)\n",
        "\n",
        "    ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "# Step 4: Create scatter plots for PCA, t-SNE, and UMAP\n",
        "plot_scatter(axes[0], X_pca_tdm, 'PCA')\n",
        "plot_scatter(axes[1], X_tsne_tdm, 't-SNE')\n",
        "plot_scatter(axes[2], X_umap_tdm, 'UMAP')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "apeLck_Lw1P4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}